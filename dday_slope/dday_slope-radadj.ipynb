{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markstro\n",
    "3/27/2020\n",
    "\n",
    "This notebook is for estimating the parameter \"dday_slope\" for GF v1.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the daily radadj value for each HRU for each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fiona \n",
    "import geopandas as gpd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrel_shapefile_fn = \"c:/Users/markstro/work1.1/GIS/nhm_shapefiles/nhm_hru_gf1_1_nrel_solrad.shp\"\n",
    "\n",
    "# This file produced by jupyter notebook \"solar_table\". It produces the same values as the soltab.f90 PRMS module.\n",
    "soltab_solt_fn = 'c:/Users/markstro/work1.1/soltab/soltab_solt_GF_v1.1.csv'\n",
    "\n",
    "# radadj is the output of this notebook\n",
    "radadj_fn = 'c:/Users/markstro/work1.1/soltab/dday_slope_radadj_GF_v1.1.csv'\n",
    "\n",
    "# This is the hru_slope value from the PRMS parameter file\n",
    "hru_slope_fn = 'c:/Users/markstro/work/input/hru_slope.csv'\n",
    "\n",
    "gdb_path = 'c:/Users/markstro/work1.1/GIS/GFv1.1_v2e.gdb'\n",
    "\n",
    "# This is the hru_slope value from the PRMS parameter file\n",
    "hru_elev_fn = 'c:/Users/markstro/work1.1/paramdb_v1.1/paramdb_master/hru_elev.csv'\n",
    "hru_slope_fn = 'c:/Users/markstro/work1.1/paramdb_v1.1/paramdb_master/hru_slope.csv'\n",
    "hru_aspect_fn = 'c:/Users/markstro/work1.1/paramdb_v1.1/paramdb_master/hru_aspect.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coolwarm = cm.get_cmap('coolwarm', 12)\n",
    "print(coolwarm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next blocks load in the monthly solrad targets from NREL Direct Normal Irradiance from http://nrel.gov/gis/solar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the monthly short wave data from NREL. It's in the shapefile that was created by running zonal means\n",
    "# on the monthly DNI geotifs downloaded from NREL.\n",
    "\n",
    "hrus = gpd.read_file(nrel_shapefile_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the order of the nhru_v11 IDs for mapping the soltab values.\n",
    "\n",
    "nhru_v11_vals = hrus[\"nhru_v11\"]\n",
    "print(nhru_v11_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For whatever reason, the zonal mean process from QGIS left some NaNs when filling in the Direct Normal Irradiance (dni)\n",
    "# monthly values in the shapefile (see dni* columns above). Those need to be filled in with real values.\n",
    "# Without going back to the GIS (which I already ran with the results that are shown above), I am using np.interpolate across\n",
    "# each column. This is a hack in the sense that the adjacent row do not necessarily mean that the HRUs are adjacent, and it\n",
    "# is uncertain exactly what is being interpolated, but it is filling in the nan values with real values and allows\n",
    "# me to move on.\n",
    "\n",
    "\n",
    "print(hrus.shape)\n",
    "\n",
    "print(\"original coordinates with nan value\")\n",
    "count = 0\n",
    "for ii in range(hrus.shape[0]):\n",
    "    for jj in range(8,20):\n",
    "        if np.isnan(hrus.iloc[ii,jj]):\n",
    "            print(\" (\", ii,jj, \")\", end = '')\n",
    "            count += 1\n",
    "print(\"\")\n",
    "print(count)\n",
    "      \n",
    "\n",
    "for ii in range(hrus.shape[0]):\n",
    "    for jj in range(8,20):\n",
    "        hrus.iloc[:,jj] = hrus.iloc[:,jj].interpolate()\n",
    "\n",
    "print(\"subsequent coordinates with nan value\")\n",
    "count = 0\n",
    "for ii in range(hrus.shape[0]):\n",
    "    for jj in range(8,20):\n",
    "        if np.isnan(hrus.iloc[ii,jj]):\n",
    "            print(\" (\", ii,jj, \")\", end = '')\n",
    "            count += 1\n",
    "\n",
    "print(\"\")\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the HRU slopes from the PRMS parmaeter file (paramdb) to the features from the shapefile.\n",
    "\n",
    "hru_slope_df = pd.read_csv(hru_slope_fn)\n",
    "hrus = hrus.set_index('nhru_v11').join(hru_slope_df.set_index('$id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the cosine of the hru slopes. The hru_slope must be converted from rise/run to radians with arctan first.\n",
    "\n",
    "hrus['hru_cossl'] = np.cos(np.arctan(hrus['hru_slope']))\n",
    "hru_cossl_vals = hrus['hru_cossl'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the NREL monthly solrad targets from the dataframe into a numpy 2D array for the radadj calculation below.\n",
    "\n",
    "solrad_targets_vals= hrus[[\"dni_jan_me\", \"dni_feb_me\", \"dni_mar_me\", \"dni_apr_me\", \"dni_may_me\", \"dni_jun_me\",\n",
    "                    \"dni_jul_me\", \"dni_aug_me\", \"dni_sep_me\", \"dni_oct_me\", \"dni_nov_me\", \"dni_dec_me\"]].values\n",
    "print(solrad_targets_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The NREL solrad values are in units of kWh/m2/Day. PRMS uses Langleys per day. The conversion factor comes from\n",
    "# https://www.wcc.nrcs.usda.gov/ftpref/wntsc/H&H/GEM/SolarRadConversion.pdf\n",
    "\n",
    "#                    W-sec    1 KW     1 hour               KW-hours\n",
    "# 1 Langley = 41868 -------  ------   -------  =   0.6978  ---------\n",
    "#                     m2     1000 W   60 sec                  m2\n",
    "\n",
    "solrad_targets_vals_langleys = solrad_targets_vals / 0.6978\n",
    "print(solrad_targets_vals_langleys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the soltab values from the csv file produced by solar_table.ipynb\n",
    "\n",
    "soltab_df = pd.read_csv(soltab_solt_fn, header=None)\n",
    "soltab_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soltab values from the csv file produced by solar_table.ipynb\n",
    "\n",
    "soltab_df_vals = soltab_df.values\n",
    "print(soltab_df_vals)\n",
    "print(soltab_df_vals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the values less than 10.0 and set them to 10.0. That gives something for the\n",
    "# radajd calculation something to work with.\n",
    "\n",
    "count = np.sum(soltab_df_vals < 10.0)\n",
    "print(count)\n",
    "print(float(count)/float(366.0 * 114958.0))\n",
    "\n",
    "soltab_df_vals[soltab_df_vals < 10.0] = 10.0\n",
    "\n",
    "print(soltab_df_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array (len = 366, number of days in the year) that for any jday, it gives the month index.\n",
    "jan = [0] * 31\n",
    "feb = [1] * 29 # assume leap year to get full table\n",
    "mar = [2] * 31\n",
    "apr = [3] * 30\n",
    "may = [4] * 31\n",
    "jun = [5] * 30\n",
    "jul = [6] * 31\n",
    "aug = [7] * 31\n",
    "sep = [8] * 30\n",
    "octo = [9] * 31\n",
    "nov = [10] * 30\n",
    "dec = [11] * 31\n",
    "\n",
    "month_of_jday = jan + feb + mar + apr + may + jun + jul + aug + sep + octo + nov + dec\n",
    "print(len(month_of_jday), month_of_jday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute radadj for all days-of-the-year and for all HRUs\n",
    "\n",
    "radadj = np.zeros(soltab_df.shape)\n",
    "nday = soltab_df.shape[0]\n",
    "nhru = soltab_df.shape[1]\n",
    "\n",
    "min_count = 0\n",
    "max_count = 0\n",
    "for jday in range(nday):\n",
    "    imon = month_of_jday[jday]\n",
    "    for ihru in range(nhru):\n",
    "        kk = nhru_v11_vals[ihru] - 1\n",
    "        try:\n",
    "            radadj[jday,ihru] = solrad_targets_vals_langleys[ihru,imon] * hru_cossl_vals[ihru] / soltab_df_vals[jday,kk]\n",
    "        except:\n",
    "            print(jday, ihru, imon, solrad_targets_vals_langleys[ihru,imon], hru_cossl_vals[ihru], soltab_df_vals[jday,kk])\n",
    "            \n",
    "        if radadj[jday,ihru] < 0.05:\n",
    "            radadj[jday,ihru] = 0.05\n",
    "            min_count += 1\n",
    "            \n",
    "        if radadj[jday,ihru] > 0.95:\n",
    "            radadj[jday,ihru] = 0.05\n",
    "            max_count += 1\n",
    "        \n",
    "print ((jday * nhru), min_count, max_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jday = 366\n",
    "\n",
    "hrus[\"solrad_targets_vals_langleys\"] = solrad_targets_vals_langleys[:,month_of_jday[jday-1]]\n",
    "print(len(hrus[\"solrad_targets_vals_langleys\"]))\n",
    "\n",
    "print(solrad_targets_vals_langleys.shape)\n",
    "print(min(solrad_targets_vals_langleys[:,month_of_jday[jday-1]]),max(solrad_targets_vals_langleys[:,month_of_jday[jday-1]]))\n",
    "\n",
    "print(min(hrus[\"solrad_targets_vals_langleys\"]),max(hrus[\"solrad_targets_vals_langleys\"]))\n",
    "\n",
    "plt.hist(solrad_targets_vals_langleys[:,month_of_jday[jday-1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(12, 12))\n",
    "#hrus.plot(color=\"white\", ax=ax)\n",
    "\n",
    "# df.dropna(thresh=2)\n",
    "\n",
    "# plot the HRUs with valid temperature (non-nan) with their color ramp colors\n",
    "hrus.plot(column='solrad_targets_vals_langleys', cmap='coolwarm', ax=ax, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(12, 12))\n",
    "#hrus.plot(color=\"white\", ax=ax)\n",
    "\n",
    "# df.dropna(thresh=2)\n",
    "\n",
    "# plot the HRUs with valid temperature (non-nan) with their color ramp colors\n",
    "hrus.plot(column='hru_cossl', cmap='coolwarm', ax=ax, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrus[\"radadj\"] = radadj[jday - 1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the radadj values\n",
    "\n",
    "# plot all HRUs in white (background color)\n",
    "f, ax = plt.subplots(1, figsize=(12, 12))\n",
    "#hrus.plot(color=\"white\", ax=ax)\n",
    "\n",
    "# df.dropna(thresh=2)\n",
    "\n",
    "# plot the HRUs with valid temperature (non-nan) with their color ramp colors\n",
    "hrus.plot(column='radadj', cmap='coolwarm', ax=ax, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hrus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write the radadj values out to csv file so all of the stuff above doesn't need to be rerun to complete the next steps.\n",
    "\n",
    "radadj_t = np.transpose(radadj)\n",
    "cols = list(range(1, 367))\n",
    "#print(cols)\n",
    "df = pd.DataFrame(data=radadj_t, columns=cols)\n",
    "df[\"nhru_v11\"] = nhru_v11_vals\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the radadj values out to csv file so all of the stuff above doesn't need to be rerun to complete the next steps.\n",
    "\n",
    "df.to_csv(path_or_buf=radadj_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
